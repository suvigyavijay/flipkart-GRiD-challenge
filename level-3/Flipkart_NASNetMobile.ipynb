{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "baAtEA1ofo_7"
   },
   "source": [
    "\n",
    "### 1.3 ResNet50V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet is almost a similar model to MobileNetV2 with comparable depth, but more parameters and size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from keras import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from keras.layers import *\n",
    "from keras.utils import Sequence\n",
    "from keras.backend import epsilon\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageEnhance\n",
    "import cv2\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 50\n",
    "\n",
    "MULTI_PROCESSING = True\n",
    "THREADS = 20\n",
    "DATA_DIR = 'images/'\n",
    "\n",
    "TRAIN_CSV = \"train.csv\"\n",
    "VALIDATION_CSV = \"validation.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPaGvbB5jTwJ"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, csv_file,rnd_rescale=True, rnd_multiply=True, rnd_color=True, rnd_crop=True, rnd_flip=True,\n",
    "                 batch_size = BATCH_SIZE, rnd_dice=True):\n",
    "        self.paths = []\n",
    "        self.coords = []\n",
    "        self.batch_size = batch_size\n",
    "        self.rnd_rescale = rnd_rescale\n",
    "        self.rnd_multiply = rnd_multiply\n",
    "        self.rnd_color = rnd_color\n",
    "        self.rnd_crop = rnd_crop\n",
    "        self.rnd_flip = rnd_flip\n",
    "        self.rnd_dice = rnd_dice\n",
    "\n",
    "        with open(csv_file, \"r\") as file:\n",
    "            self.coords = np.zeros((sum(1 for line in file)-1, 4))\n",
    "            \n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            path = os.path.join(DATA_DIR, row['image_name'])\n",
    "            x1 = row['x1']\n",
    "            x2 = row['x2']\n",
    "            y1 = row['y1']\n",
    "            y2 = row['y2']\n",
    "\n",
    "            img = Image.open(path)\n",
    "            width, height = img.size\n",
    "\n",
    "            self.coords[index, 0] = x1\n",
    "            self.coords[index, 1] = y1\n",
    "            self.coords[index, 2] = x2 \n",
    "            self.coords[index, 3] = y2 \n",
    "\n",
    "            self.paths.append(path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.coords)*2 / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.paths[idx * self.batch_size//2:(idx + 1) * self.batch_size//2]\n",
    "        coords = self.coords[idx * self.batch_size//2:(idx + 1) * self.batch_size//2].copy()\n",
    "        batch_coords = np.zeros((self.batch_size,4))\n",
    "        batch_images = np.zeros((self.batch_size, IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.float32)\n",
    "        i = 0\n",
    "        for j, f in enumerate(batch_paths):\n",
    "            img = Image.open(f)\n",
    "            x0,y0,x1,y1 = coords[j]\n",
    "            image_width = img.width\n",
    "            image_height = img.height\n",
    "            img2 = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "            img2 = img2.convert('RGB')\n",
    "            img2 = np.array(img2, dtype=np.float32)\n",
    "            batch_images[i] = preprocess_input(img2.copy())\n",
    "            \n",
    "            batch_coords[i, 0] = x0 * IMAGE_SIZE / image_width\n",
    "            batch_coords[i, 1] = y0 * IMAGE_SIZE / image_height\n",
    "            batch_coords[i, 2] = (x1 - x0) * IMAGE_SIZE / image_width\n",
    "            batch_coords[i, 3] = (y1 - y0) * IMAGE_SIZE / image_height \n",
    "            \n",
    "            if self.rnd_dice:\n",
    "                \n",
    "#                 select = np.random.randint(5)\n",
    "                \n",
    "                if self.rnd_rescale:\n",
    "                    old_width = img.width\n",
    "                    old_height = img.height\n",
    "\n",
    "                    rescale = np.random.uniform(low=0.6, high=1.4)\n",
    "                    new_width = int(old_width * rescale)\n",
    "                    new_height = int(old_height * rescale)\n",
    "\n",
    "                    img = img.resize((new_width, new_height))\n",
    "\n",
    "                    x0 *= new_width / old_width\n",
    "                    y0 *= new_height / old_height\n",
    "                    x1 *= new_width / old_width\n",
    "                    y1 *= new_height / old_height\n",
    "\n",
    "                if self.rnd_crop:\n",
    "                    start_x = np.random.randint(0, high=np.floor(0.15 * img.width))\n",
    "                    stop_x = img.width - np.random.randint(0, high=np.floor(0.15 * img.width))\n",
    "                    start_y = np.random.randint(0, high=np.floor(0.15 * img.height))\n",
    "                    stop_y = img.height - np.random.randint(0, high=np.floor(0.15 * img.height))\n",
    "\n",
    "                    img_temp = img.copy()\n",
    "                    img = img.crop((start_x, start_y, stop_x, stop_y))\n",
    "                    \n",
    "                    x0_temp = x0\n",
    "                    x1_temp = x1\n",
    "                    y0_temp = y0\n",
    "                    y1_temp = y1\n",
    "\n",
    "                    x0 = max(x0 - start_x, 0)\n",
    "                    y0 = max(y0 - start_y, 0)\n",
    "                    x1 = min(x1 - start_x, img.width)\n",
    "                    y1 = min(y1 - start_y, img.height)\n",
    "\n",
    "                    if np.abs(x1 - x0) < 40 or np.abs(y1 - y0) < 40:\n",
    "                        img = img_temp\n",
    "                        x0 = x0_temp\n",
    "                        x1 = x1_temp\n",
    "                        y0 = y0_temp\n",
    "                        y1 = y1_temp\n",
    "#                         print(\"\\nWarning: cropped too much (obj width {}, obj height {}, img width {}, img height {})\\n\".format(x1 - x0, y1 - y0, img.width, img.height))\n",
    "\n",
    "                if self.rnd_flip:\n",
    "                    elem = np.random.choice([0, 90, 180, 270, 1423, 1234])\n",
    "                    if elem % 10 == 0:\n",
    "                        x = x0 - img.width / 2\n",
    "                        y = y0 - img.height / 2\n",
    "\n",
    "                        x0 = img.width / 2 + x * np.cos(np.deg2rad(elem)) - y * np.sin(np.deg2rad(elem))\n",
    "                        y0 = img.height / 2 + x * np.sin(np.deg2rad(elem)) + y * np.cos(np.deg2rad(elem))\n",
    "\n",
    "                        x = x1 - img.width / 2\n",
    "                        y = y1 - img.height / 2\n",
    "\n",
    "                        x1 = img.width / 2 + x * np.cos(np.deg2rad(elem)) - y * np.sin(np.deg2rad(elem))\n",
    "                        y1 = img.height / 2 + x * np.sin(np.deg2rad(elem)) + y * np.cos(np.deg2rad(elem))\n",
    "\n",
    "                        img = img.rotate(-elem)\n",
    "                    else:\n",
    "                        if elem == 1423:\n",
    "                            img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "                            y0 = img.height - y0\n",
    "                            y1 = img.height - y1\n",
    "\n",
    "                        elif elem == 1234:\n",
    "                            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                            x0 = img.width - x0\n",
    "                            x1 = img.width - x1\n",
    "\n",
    "                image_width = img.width\n",
    "                image_height = img.height\n",
    "\n",
    "                tmp = x0\n",
    "                x0 = min(x0, x1)\n",
    "                x1 = max(tmp, x1)\n",
    "\n",
    "                tmp = y0\n",
    "                y0 = min(y0, y1)\n",
    "                y1 = max(tmp, y1)\n",
    "\n",
    "                x0 = max(x0, 0)\n",
    "                y0 = max(y0, 0)\n",
    "\n",
    "                y0 = min(y0, image_height)\n",
    "                x0 = min(x0, image_width)\n",
    "                y1 = min(y1, image_height)\n",
    "                x1 = min(x1, image_width)\n",
    "\n",
    "                if self.rnd_color:\n",
    "                    enhancer = ImageEnhance.Color(img)\n",
    "                    img = enhancer.enhance(np.random.uniform(low=0.5, high=1.5))\n",
    "\n",
    "                    enhancer2 = ImageEnhance.Brightness(img)\n",
    "                    img = enhancer.enhance(np.random.uniform(low=0.7, high=1.3))\n",
    "\n",
    "                img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "                img = img.convert('RGB')\n",
    "                pil_img = img\n",
    "                img = np.array(img, dtype=np.float32)\n",
    "                pil_img.close()\n",
    "                \n",
    "                if self.rnd_multiply:\n",
    "                    img[...,0] = np.floor(np.clip(img[...,0] * np.random.uniform(low=0.8, high=1.2), 0.0, 255.0))\n",
    "                    img[...,1] = np.floor(np.clip(img[...,1] * np.random.uniform(low=0.8, high=1.2), 0.0, 255.0))\n",
    "                    img[...,2] = np.floor(np.clip(img[...,2] * np.random.uniform(low=0.8, high=1.2), 0.0, 255.0))\n",
    "\n",
    "                batch_images[i+1] = preprocess_input(img.copy())\n",
    "\n",
    "                batch_coords[i+1, 0] = x0 * IMAGE_SIZE / image_width\n",
    "                batch_coords[i+1, 1] = y0 * IMAGE_SIZE / image_height\n",
    "                batch_coords[i+1, 2] = (x1 - x0) * IMAGE_SIZE / image_width\n",
    "                batch_coords[i+1, 3] = (y1 - y0) * IMAGE_SIZE / image_height \n",
    "                \n",
    "            i+=2\n",
    "            \n",
    "        return batch_images, batch_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JhVbeIlTojCm"
   },
   "outputs": [],
   "source": [
    "def IOU(y_true, y_pred):\n",
    "    diff_width = K.minimum(y_true[:,0] + y_true[:,2], y_pred[:,0] + y_pred[:,2]) - K.maximum(y_true[:,0], y_pred[:,0])\n",
    "    diff_height = K.minimum(y_true[:,1] + y_true[:,3], y_pred[:,1] + y_pred[:,3]) - K.maximum(y_true[:,1], y_pred[:,1])\n",
    "    intersection = K.maximum(diff_width, 0) * K.maximum(diff_height, 0)\n",
    "\n",
    "    area_gt = y_true[:,2] * y_true[:,3]\n",
    "    area_pred = y_pred[:,2] * y_pred[:,3]\n",
    "    union = K.maximum(area_gt + area_pred - intersection, 0)\n",
    "\n",
    "    #ntersection = K.sum(intersection * (union > 0))\n",
    "    intersection = K.tf.where(union > 0, intersection, K.zeros_like(intersection))\n",
    "    intersection = K.sum(intersection)\n",
    "    union = K.sum(union)\n",
    "    iou = (intersection / (union + epsilon()))\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8ASAG6asrNL"
   },
   "source": [
    "### Loading Validation Data into the Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNsSCUissyZe"
   },
   "source": [
    "Unlike training data validation can still be performed via loading data into memory, and will help improve training time. Also, as we are not doing any augmentation in the validation data we can save some time by defining another data generator just for validation purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Pl-DtaDtXfi"
   },
   "outputs": [],
   "source": [
    "from keras.applications.nasnet import preprocess_input\n",
    "\n",
    "valData = pd.read_csv('validation.csv')\n",
    "\n",
    "val_coords = np.zeros((len(valData),4))\n",
    "val_images = np.zeros((len(valData), IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.float32)\n",
    "\n",
    "for index, row in valData.iterrows():\n",
    "    path = os.path.join(DATA_DIR, row['image_name'])\n",
    "    x1 = row['x1']\n",
    "    x2 = row['x2']\n",
    "    y1 = row['y1']\n",
    "    y2 = row['y2']\n",
    "\n",
    "    img = Image.open(path)\n",
    "    width, height = img.size\n",
    "\n",
    "    val_coords[index, 0] = x1*IMAGE_SIZE / width\n",
    "    val_coords[index, 1] = y1*IMAGE_SIZE / height\n",
    "    val_coords[index, 2] = (x2 - x1)* IMAGE_SIZE / width\n",
    "    val_coords[index, 3] = (y2 - y1)*IMAGE_SIZE / height \n",
    "    \n",
    "    img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    img = img.convert('RGB')\n",
    "    pil_img = img\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    val_images[index] = preprocess_input(img.copy())\n",
    "    pil_img.close()\n",
    "\n",
    "class ValDataGenerator(Sequence):\n",
    "    def __init__(self, val_images, val_coords, batch_size = BATCH_SIZE):\n",
    "        self.images = val_images\n",
    "        self.coords = val_coords\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.coords) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_coords = self.coords[idx * self.batch_size:(idx + 1) * self.batch_size].copy()\n",
    "        batch_images = self.images[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_images, batch_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzNaKceXvk8v"
   },
   "source": [
    "Let's go ahead and define our model, having base model as DenseNet121."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AWKqFpMpvlKD"
   },
   "outputs": [],
   "source": [
    "from keras.applications.nasnet import NASNetMobile\n",
    "\n",
    "def nasnet_model(trainable=True):\n",
    "    model = NASNetMobile(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    x = model.layers[-1].output\n",
    "    x = Conv2D(256, kernel_size=3, name=\"mn1\", activation='relu')(x)\n",
    "    x = Conv2D(4, kernel_size=5, name=\"mn2\", activation='relu')(x)\n",
    "    x = Reshape((4,))(x)\n",
    "\n",
    "    return Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwS5AJhjxH0j"
   },
   "source": [
    "**Note: We have set `weights=None` because of the competition requirements of \"no transfer learning\" on the discussion board, but setting `weights='imagenet'` improves the prediction as well as the training time.**\n",
    "\n",
    "\n",
    "Currently, weights are initialized randomly and thus takes a lot more time to train than starting off with imagenet weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5749
    },
    "colab_type": "code",
    "id": "CMsxW37syqOx",
    "outputId": "437c7dbb-7505-4837-fac5-d62f0febf499"
   },
   "outputs": [],
   "source": [
    "nnmob = nasnet_model()\n",
    "nnmob.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yM1kepEHzbjP"
   },
   "source": [
    "Now that we have defined the model, let's compile it and intialize other variables for training including checkpoint, early stopping and scheduling learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDZa-RYa0ZDK"
   },
   "outputs": [],
   "source": [
    "nnmob.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['accuracy',IOU])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"nasnet-{val_IOU:.2f}.h5\", monitor=\"val_IOU\", verbose=1, save_best_only=True, save_weights_only=True, mode=\"max\", period=1)\n",
    "\n",
    "stop = EarlyStopping(monitor=\"val_IOU\", patience=PATIENCE, mode=\"max\")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_IOU\", factor=0.2, patience=5, min_lr=1e-7, verbose=1, mode=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqp0dCqv0iGj"
   },
   "source": [
    "Now, let's finally intialize our data generators and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4aNySdL0s4I"
   },
   "outputs": [],
   "source": [
    "train_datagen = DataGenerator(TRAIN_CSV)\n",
    "validation_datagen = ValDataGenerator(val_images, val_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2bZ70770tKp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1425/1425 [==============================] - 603s 423ms/step - loss: 21.9125 - acc: 0.7927 - IOU: 0.5882 - val_loss: 14.6411 - val_acc: 0.9108 - val_IOU: 0.5907\n",
      "\n",
      "Epoch 00001: val_IOU improved from -inf to 0.59068, saving model to nasnet-0.59.h5\n",
      "Epoch 2/500\n",
      "1425/1425 [==============================] - 540s 379ms/step - loss: 19.2854 - acc: 0.8199 - IOU: 0.6176 - val_loss: 17.2029 - val_acc: 0.9125 - val_IOU: 0.5286\n",
      "\n",
      "Epoch 00002: val_IOU did not improve from 0.59068\n",
      "Epoch 3/500\n",
      "1425/1425 [==============================] - 543s 381ms/step - loss: 18.7872 - acc: 0.8227 - IOU: 0.6234 - val_loss: 25.5679 - val_acc: 0.8775 - val_IOU: 0.3892\n",
      "\n",
      "Epoch 00003: val_IOU did not improve from 0.59068\n",
      "Epoch 4/500\n",
      "\n",
      "Epoch 00002: val_IOU did not improve from 0.59068\n",
      "Epoch 3/500\n",
      "1425/1425 [==============================] - 542s 381ms/step - loss: 18.6153 - acc: 0.8252 - IOU: 0.6250 - val_loss: 33.7532 - val_acc: 0.8908 - val_IOU: 0.2775\n",
      "\n",
      "Epoch 00004: val_IOU did not improve from 0.59068\n",
      "Epoch 5/500\n",
      "1425/1425 [==============================] - 543s 381ms/step - loss: 18.4648 - acc: 0.8303 - IOU: 0.6267 - val_loss: 37.5461 - val_acc: 0.8842 - val_IOU: 0.2327\n",
      "\n",
      "Epoch 00005: val_IOU did not improve from 0.59068\n",
      "Epoch 6/500\n",
      " 636/1425 [============>.................] - ETA: 5:00 - loss: 18.2077 - acc: 0.8281 - IOU: 0.6308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425/1425 [==============================] - 542s 380ms/step - loss: 18.1928 - acc: 0.8283 - IOU: 0.6301 - val_loss: 35.3110 - val_acc: 0.8683 - val_IOU: 0.2570\n",
      "\n",
      "Epoch 00006: val_IOU did not improve from 0.59068\n",
      "Epoch 7/500\n",
      "1425/1425 [==============================] - 542s 381ms/step - loss: 18.0455 - acc: 0.8320 - IOU: 0.6311 - val_loss: 42.9736 - val_acc: 0.8600 - val_IOU: 0.1791\n",
      "\n",
      "Epoch 00007: val_IOU did not improve from 0.59068\n",
      "Epoch 8/500\n",
      "1425/1425 [==============================] - 548s 384ms/step - loss: 17.9872 - acc: 0.8329 - IOU: 0.6318 - val_loss: 22.7443 - val_acc: 0.8975 - val_IOU: 0.4272\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00008: val_IOU did not improve from 0.59068\n",
      "Epoch 9/500\n",
      " 581/1425 [===========>..................] - ETA: 5:19 - loss: 17.1728 - acc: 0.8391 - IOU: 0.6433"
     ]
    }
   ],
   "source": [
    "nnmob.fit_generator(generator=train_datagen,\n",
    "                    validation_data=validation_datagen, \n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[reduce_lr, stop, checkpoint],\n",
    "                    workers=THREADS,\n",
    "                    use_multiprocessing=MULTI_PROCESSING,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4ZF1TXNRfFU"
   },
   "source": [
    "After training, we need to load weights from the best validation IoU file we got, and then make predictions on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61k4sPVMRxyM"
   },
   "outputs": [],
   "source": [
    "## Since the models will take a huge amount of time to train, you can download the trained weights from \n",
    "## this Google Drive folder into the directory\n",
    "## https://drive.google.com/drive/folders/1rOVkxqHaCKjamji7c3XfdomvMbqksgU6?usp=sharing\n",
    "\n",
    "WEIGHTS_FILE = \"nasnet-0.90.h5\"\n",
    "\n",
    "nnmob.load_weights(WEIGHTS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Vg5TQ7jkR-_t",
    "outputId": "aeb86cab-d9f3-433c-8a60-206982155d29"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "as86LS6VSEVD",
    "outputId": "ea6ccafd-236a-45ad-edec-9361fbb90558"
   },
   "outputs": [],
   "source": [
    "for index, row in test.iterrows():\n",
    "    unscaled = cv2.imread(DATA_DIR+row['image_name'])\n",
    "    image_height, image_width, _ = unscaled.shape\n",
    "\n",
    "    image = cv2.resize(unscaled, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
    "\n",
    "    region = nnmob.predict(x=np.array([feat_scaled]))[0]\n",
    "\n",
    "    x1 = (region[0] * image_width / IMAGE_SIZE)\n",
    "    y1 = (region[1] * image_height / IMAGE_SIZE)\n",
    "\n",
    "    x2 = ((region[0] + region[2]) * image_width / IMAGE_SIZE)\n",
    "    y2 = ((region[1] + region[3]) * image_height / IMAGE_SIZE)\n",
    "\n",
    "    test.iloc[index,1] = x1\n",
    "    test.iloc[index,2] = x2\n",
    "    test.iloc[index,3] = y1\n",
    "    test.iloc[index,4] = y2\n",
    "    \n",
    "    if index%1000==0:\n",
    "        print(index)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Fo_uhvDSV82"
   },
   "outputs": [],
   "source": [
    "test.to_csv('nnmob-prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKT82ksdibVQ"
   },
   "source": [
    "Since we also require predictions on the complete training and validation set, we will also create and save CSV files for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ImXv3Sxmig6z"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"training_set.csv\")\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    unscaled = cv2.imread(DATA_DIR+row['image_name'])\n",
    "    image_height, image_width, _ = unscaled.shape\n",
    "\n",
    "    image = cv2.resize(unscaled, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
    "\n",
    "    region = nnmob.predict(x=np.array([feat_scaled]))[0]\n",
    "\n",
    "    x1 = (region[0] * image_width / IMAGE_SIZE)\n",
    "    y1 = (region[1] * image_height / IMAGE_SIZE)\n",
    "\n",
    "    x2 = ((region[0] + region[2]) * image_width / IMAGE_SIZE)\n",
    "    y2 = ((region[1] + region[3]) * image_height / IMAGE_SIZE)\n",
    "\n",
    "    train.iloc[index,1] = x1\n",
    "    train.iloc[index,2] = x2\n",
    "    train.iloc[index,3] = y1\n",
    "    train.iloc[index,4] = y2\n",
    "    \n",
    "    if index%1000==0:\n",
    "        print(index)\n",
    "    \n",
    "train.to_csv('nnmob-training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
