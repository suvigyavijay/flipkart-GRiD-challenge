{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageEnhance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.layers import Conv2D, Reshape, DepthwiseConv2D, ZeroPadding2D\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.backend import epsilon\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_DIR = \"images\"\n",
    "\n",
    "# 0.35, 0.5, 0.75, 1.0, 1.3, 1.4\n",
    "ALPHA = 1.3\n",
    "\n",
    "# 96, 128, 160, 192, 224\n",
    "IMAGE_SIZE = 299\n",
    "\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 24\n",
    "PATIENCE = 50\n",
    "\n",
    "MULTI_PROCESSING = True\n",
    "THREADS = 12\n",
    "\n",
    "data = pd.read_csv('training.csv')\n",
    "train, test = train_test_split(data, test_size=0.1, random_state=123)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('validation.csv', index=False)\n",
    "\n",
    "TRAIN_CSV = \"train.csv\"\n",
    "VALIDATION_CSV = \"validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, csv_file,rnd_rescale=True, rnd_multiply=True, rnd_color=True, rnd_crop=True, rnd_flip=False,\n",
    "                 batch_size = BATCH_SIZE):\n",
    "        self.paths = []\n",
    "        self.coords = []\n",
    "        self.batch_size = batch_size\n",
    "        self.rnd_rescale = rnd_rescale\n",
    "        self.rnd_multiply = rnd_multiply\n",
    "        self.rnd_color = rnd_color\n",
    "        self.rnd_crop = rnd_crop\n",
    "        self.rnd_flip = rnd_flip\n",
    "\n",
    "        with open(csv_file, \"r\") as file:\n",
    "            self.coords = np.zeros((sum(1 for line in file)-1, 4))\n",
    "            \n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            path = os.path.join(DATA_DIR, row['image_name'])\n",
    "            x1 = row['x1']\n",
    "            x2 = row['x2']\n",
    "            y1 = row['y1']\n",
    "            y2 = row['y2']\n",
    "\n",
    "            img = Image.open(path)\n",
    "            width, height = img.size\n",
    "\n",
    "            self.coords[index, 0] = x1\n",
    "            self.coords[index, 1] = y1\n",
    "            self.coords[index, 2] = x2 \n",
    "            self.coords[index, 3] = y2 \n",
    "\n",
    "            self.paths.append(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.coords) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_coords = self.coords[idx * self.batch_size:(idx + 1) * self.batch_size].copy()\n",
    "\n",
    "        batch_images = np.zeros((len(batch_paths), IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.float32)\n",
    "        for i, f in enumerate(batch_paths):\n",
    "            img = Image.open(f)\n",
    "            x0,y0,x1,y1 = batch_coords[i]\n",
    "            if self.rnd_rescale:\n",
    "                old_width = img.width\n",
    "                old_height = img.height\n",
    "\n",
    "                rescale = np.random.uniform(low=0.6, high=1.4)\n",
    "                new_width = int(old_width * rescale)\n",
    "                new_height = int(old_height * rescale)\n",
    "\n",
    "                img = img.resize((new_width, new_height))\n",
    "\n",
    "                x0 *= new_width / old_width\n",
    "                y0 *= new_height / old_height\n",
    "                x1 *= new_width / old_width\n",
    "                y1 *= new_height / old_height\n",
    "\n",
    "            if self.rnd_crop:\n",
    "                start_x = np.random.randint(0, high=np.floor(0.15 * img.width))\n",
    "                stop_x = img.width - np.random.randint(start_x, high=np.floor(0.15 * img.width))\n",
    "                start_y = np.random.randint(0, high=np.floor(0.15 * img.height))\n",
    "                stop_y = img.height - np.random.randint(start_y, high=np.floor(0.15 * img.height))\n",
    "\n",
    "                img = img.crop((start_x, start_y, stop_x, stop_y))\n",
    "\n",
    "                x0 = max(x0 - start_x, 0)\n",
    "                y0 = max(y0 - start_y, 0)\n",
    "                x1 = min(x1 - start_x, img.width)\n",
    "                y1 = min(y1 - start_y, img.height)\n",
    "\n",
    "                if np.abs(x1 - x0) < 5 or np.abs(y1 - y0) < 5:\n",
    "                    print(\"\\nWarning: cropped too much (obj width {}, obj height {}, img width {}, img height {})\\n\".format(x1 - x0, y1 - y0, img.width, img.height))\n",
    "\n",
    "            if self.rnd_flip:\n",
    "                elem = np.random.choice([0, 90, 180, 270, 1423, 1234])\n",
    "                if elem % 10 == 0:\n",
    "                    x = x0 - img.width / 2\n",
    "                    y = y0 - img.height / 2\n",
    "\n",
    "                    x0 = img.width / 2 + x * np.cos(np.deg2rad(elem)) - y * np.sin(np.deg2rad(elem))\n",
    "                    y0 = img.height / 2 + x * np.sin(np.deg2rad(elem)) + y * np.cos(np.deg2rad(elem))\n",
    "\n",
    "                    x = x1 - img.width / 2\n",
    "                    y = y1 - img.height / 2\n",
    "\n",
    "                    x1 = img.width / 2 + x * np.cos(np.deg2rad(elem)) - y * np.sin(np.deg2rad(elem))\n",
    "                    y1 = img.height / 2 + x * np.sin(np.deg2rad(elem)) + y * np.cos(np.deg2rad(elem))\n",
    "\n",
    "                    img = img.rotate(-elem)\n",
    "                else:\n",
    "                    if elem == 1423:\n",
    "                        img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "                        y0 = img.height - y0\n",
    "                        y1 = img.height - y1\n",
    "\n",
    "                    elif elem == 1234:\n",
    "                        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                        x0 = img.width - x0\n",
    "                        x1 = img.width - x1\n",
    "\n",
    "            image_width = img.width\n",
    "            image_height = img.height\n",
    "\n",
    "            tmp = x0\n",
    "            x0 = min(x0, x1)\n",
    "            x1 = max(tmp, x1)\n",
    "\n",
    "            tmp = y0\n",
    "            y0 = min(y0, y1)\n",
    "            y1 = max(tmp, y1)\n",
    "\n",
    "            x0 = max(x0, 0)\n",
    "            y0 = max(y0, 0)\n",
    "\n",
    "            y0 = min(y0, image_height)\n",
    "            x0 = min(x0, image_width)\n",
    "            y1 = min(y1, image_height)\n",
    "            x1 = min(x1, image_width)\n",
    "\n",
    "            if self.rnd_color:\n",
    "                enhancer = ImageEnhance.Color(img)\n",
    "                img = enhancer.enhance(np.random.uniform(low=0.5, high=1.5))\n",
    "\n",
    "                enhancer2 = ImageEnhance.Brightness(img)\n",
    "                img = enhancer.enhance(np.random.uniform(low=0.7, high=1.3))\n",
    "\n",
    "            img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "            img = img.convert('RGB')\n",
    "            pil_img = img\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "            pil_img.close()\n",
    "            if self.rnd_multiply:\n",
    "                img[...,0] = np.floor(np.clip(img[...,0] * np.random.uniform(low=0.8, high=1.2), 0.0, 255.0))\n",
    "                img[...,1] = np.floor(np.clip(img[...,1] * np.random.uniform(low=0.8, high=1.2), 0.0, 255.0))\n",
    "                img[...,2] = np.floor(np.clip(img[...,2] * np.random.uniform(low=0.8, high=1.2), 0.0, 255.0))\n",
    "\n",
    "            batch_images[i] = preprocess_input(img.copy())\n",
    "            \n",
    "            batch_coords[i, 0] = x0 * IMAGE_SIZE / image_width\n",
    "            batch_coords[i, 1] = y0 * IMAGE_SIZE / image_height\n",
    "            batch_coords[i, 2] = (x1 - x0) * IMAGE_SIZE / image_width\n",
    "            batch_coords[i, 3] = (y1 - y0) * IMAGE_SIZE / image_height \n",
    "\n",
    "        return batch_images, batch_coords\n",
    "            \n",
    "        return np.concatenate((batch_images, batch_images_rotate90)), np.concatenate((batch_coords, batch_coords_rotate90))\n",
    "class Validation(Callback):\n",
    "    def __init__(self, generator):\n",
    "        self.generator = generator\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        mse = 0\n",
    "        intersections = 0\n",
    "        unions = 0\n",
    "\n",
    "        for i in range(len(self.generator)):\n",
    "            batch_images, gt = self.generator[i]\n",
    "            pred = self.model.predict_on_batch(batch_images)\n",
    "            mse += np.linalg.norm(gt - pred, ord='fro') / pred.shape[0]\n",
    "\n",
    "            pred = np.maximum(pred, 0)\n",
    "\n",
    "            diff_width = np.minimum(gt[:,0] + gt[:,2], pred[:,0] + pred[:,2]) - np.maximum(gt[:,0], pred[:,0])\n",
    "            diff_height = np.minimum(gt[:,1] + gt[:,3], pred[:,1] + pred[:,3]) - np.maximum(gt[:,1], pred[:,1])\n",
    "            intersection = np.maximum(diff_width, 0) * np.maximum(diff_height, 0)\n",
    "\n",
    "            area_gt = gt[:,2] * gt[:,3]\n",
    "            area_pred = pred[:,2] * pred[:,3]\n",
    "            union = np.maximum(area_gt + area_pred - intersection, 0)\n",
    "\n",
    "            intersections += np.sum(intersection * (union > 0))\n",
    "            unions += np.sum(union)\n",
    "\n",
    "        iou = np.round(intersections / (unions + epsilon()), 4)\n",
    "        logs[\"val_iou\"] = iou\n",
    "\n",
    "        mse = np.round(mse, 4)\n",
    "        logs[\"val_mse\"] = mse\n",
    "\n",
    "        print(\" - val_iou: {} - val_mse: {}\".format(iou, mse))\n",
    "\n",
    "def create_irv2(trainable=False):\n",
    "    model = InceptionResNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights=None)\n",
    "\n",
    "    # to freeze layers\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = model.layers[-1].output\n",
    "    x = Conv2D(512, kernel_size=4, name=\"coords1\", activation='relu')(x)\n",
    "    x = Conv2D(256, kernel_size=3, name=\"coords2\", activation='relu')(x)\n",
    "    x = Conv2D(4, kernel_size=3, name=\"coords3\", activation='relu')(x)\n",
    "    x = Reshape((4,))(x)\n",
    "\n",
    "    return Model(inputs=model.input, outputs=x)\n",
    "\n",
    "def create_mnv2(trainable=False):\n",
    "    model = MobileNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, alpha=ALPHA, weights=None)\n",
    "\n",
    "    # to freeze layers\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = model.layers[-1].output\n",
    "    x = Conv2D(256, kernel_size=3, name=\"coords1\", activation='relu')(x)\n",
    "    x = Conv2D(4, kernel_size=5, name=\"coords2\", activation='relu')(x)\n",
    "    x = Reshape((4,))(x)\n",
    "\n",
    "    return Model(inputs=model.input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [] and type float\n\t [[node Conv1_2/kernel/Initializer/random_uniform/sub (defined at /usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet_v2.py:347)  = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 0.24902913>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'Conv1_2/kernel/Initializer/random_uniform/sub', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-e63d85c93007>\", line 1, in <module>\n    mnv2 = create_mnv2()\n  File \"<ipython-input-2-e50b28a7c26d>\", line 203, in create_mnv2\n    model = MobileNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, alpha=ALPHA, weights=None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/applications/__init__.py\", line 70, in wrapper\n    return base_fun(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/applications/mobilenet_v2.py\", line 32, in MobileNetV2\n    return mobilenet_v2.MobileNetV2(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet_v2.py\", line 347, in MobileNetV2\n    name='Conv1')(x)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 746, in __call__\n    self.build(input_shapes)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/convolutional.py\", line 165, in build\n    dtype=self.dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 609, in add_weight\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpointable/base.py\", line 639, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1977, in make_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2437, in default_variable_creator\n    import_scope=import_scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 297, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 409, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1959, in <lambda>\n    shape, dtype=dtype, partition_info=partition_info)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py\", line 486, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/random_ops.py\", line 244, in random_uniform\n    return math_ops.add(rnd * (maxval - minval), minval, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 866, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 8318, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [] and type float\n\t [[node Conv1_2/kernel/Initializer/random_uniform/sub (defined at /usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet_v2.py:347)  = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 0.24902913>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [] and type float\n\t [[{{node Conv1_2/kernel/Initializer/random_uniform/sub}} = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 0.24902913>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e63d85c93007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmnv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mnv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmnv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mobilenetV2-no-weights-all_layers-0.91.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# irv2 = create_irv2()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# irv2.load_weights('inception_resnetV2-no_weights-freeze-0.91.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1542\u001b[0m         \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m         \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    804\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[1;32m    805\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m   \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2782\u001b[0m         \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2784\u001b[0;31m       \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    467\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    736\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [] and type float\n\t [[node Conv1_2/kernel/Initializer/random_uniform/sub (defined at /usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet_v2.py:347)  = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 0.24902913>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'Conv1_2/kernel/Initializer/random_uniform/sub', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-e63d85c93007>\", line 1, in <module>\n    mnv2 = create_mnv2()\n  File \"<ipython-input-2-e50b28a7c26d>\", line 203, in create_mnv2\n    model = MobileNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, alpha=ALPHA, weights=None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/applications/__init__.py\", line 70, in wrapper\n    return base_fun(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/applications/mobilenet_v2.py\", line 32, in MobileNetV2\n    return mobilenet_v2.MobileNetV2(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet_v2.py\", line 347, in MobileNetV2\n    name='Conv1')(x)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 746, in __call__\n    self.build(input_shapes)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/convolutional.py\", line 165, in build\n    dtype=self.dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 609, in add_weight\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpointable/base.py\", line 639, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1977, in make_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2437, in default_variable_creator\n    import_scope=import_scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 297, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 409, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1959, in <lambda>\n    shape, dtype=dtype, partition_info=partition_info)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py\", line 486, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/random_ops.py\", line 244, in random_uniform\n    return math_ops.add(rnd * (maxval - minval), minval, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 866, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 8318, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [] and type float\n\t [[node Conv1_2/kernel/Initializer/random_uniform/sub (defined at /usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet_v2.py:347)  = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 0.24902913>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "mnv2 = create_mnv2()\n",
    "mnv2.load_weights('mobilenetV2-no-weights-all_layers-0.91.h5')\n",
    "\n",
    "irv2 = create_irv2()\n",
    "irv2.load_weights('inception_resnetV2-no_weights-freeze-0.91.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1474724014247DSC07926.png</td>\n",
       "      <td>258</td>\n",
       "      <td>424</td>\n",
       "      <td>96</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JPEG_20160623_170956_1000885486700.png</td>\n",
       "      <td>293</td>\n",
       "      <td>583</td>\n",
       "      <td>134</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147185868090020160818_111244.png</td>\n",
       "      <td>112</td>\n",
       "      <td>478</td>\n",
       "      <td>2</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JPEG_20160513_115642_1000775593523.png</td>\n",
       "      <td>83</td>\n",
       "      <td>589</td>\n",
       "      <td>168</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPEG_20161118_133812_1000159834754.png</td>\n",
       "      <td>172</td>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_name   x1   x2   y1   y2\n",
       "0               1474724014247DSC07926.png  258  424   96  381\n",
       "1  JPEG_20160623_170956_1000885486700.png  293  583  134  359\n",
       "2        147185868090020160818_111244.png  112  478    2  452\n",
       "3  JPEG_20160513_115642_1000775593523.png   83  589  168  398\n",
       "4  JPEG_20161118_133812_1000159834754.png  172  519    0  480"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"train.csv\")\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for filename in glob.glob(IMAGES)[8000:8010]:\n",
    "    unscaled = cv2.imread(filename)\n",
    "    image_height, image_width, _ = unscaled.shape\n",
    "\n",
    "    image = cv2.resize(unscaled, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
    "\n",
    "    region = model.predict(x=np.array([feat_scaled]))[0]\n",
    "\n",
    "    x0 = int(region[0] * image_width / IMAGE_SIZE)\n",
    "    y0 = int(region[1] * image_height / IMAGE_SIZE)\n",
    "\n",
    "    x1 = int((region[0] + region[2]) * image_width / IMAGE_SIZE)\n",
    "    y1 = int((region[1] + region[3]) * image_height / IMAGE_SIZE)\n",
    "\n",
    "    cv2.rectangle(unscaled, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "    plt.imshow(unscaled)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1474723840903DSC08089.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1473231475010DeeplearnS11276.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JPEG_20161205_135307_1000155917326.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JPEG_20160711_123440_1000518778437.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPEG_20160803_115329_100034020722.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_name  x1  x2  y1  y2\n",
       "0               1474723840903DSC08089.png NaN NaN NaN NaN\n",
       "1        1473231475010DeeplearnS11276.png NaN NaN NaN NaN\n",
       "2  JPEG_20161205_135307_1000155917326.png NaN NaN NaN NaN\n",
       "3  JPEG_20160711_123440_1000518778437.png NaN NaN NaN NaN\n",
       "4   JPEG_20160803_115329_100034020722.png NaN NaN NaN NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"test.csv\")\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1474723840903DSC08089.png</td>\n",
       "      <td>231.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1473231475010DeeplearnS11276.png</td>\n",
       "      <td>79.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JPEG_20161205_135307_1000155917326.png</td>\n",
       "      <td>140.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JPEG_20160711_123440_1000518778437.png</td>\n",
       "      <td>216.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPEG_20160803_115329_100034020722.png</td>\n",
       "      <td>127.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>428.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_name     x1     x2     y1     y2\n",
       "0               1474723840903DSC08089.png  231.0  440.0   88.0  408.0\n",
       "1        1473231475010DeeplearnS11276.png   79.0  570.0  141.0  349.0\n",
       "2  JPEG_20161205_135307_1000155917326.png  140.0  494.0   53.0  437.0\n",
       "3  JPEG_20160711_123440_1000518778437.png  216.0  458.0   97.0  417.0\n",
       "4   JPEG_20160803_115329_100034020722.png  127.0  501.0   45.0  428.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in sample.iterrows():\n",
    "    \n",
    "    unscaled = cv2.imread('images/'+row['image_name'])\n",
    "    image_height, image_width, _ = unscaled.shape\n",
    "    \n",
    "    IMAGE_SIZE = 299\n",
    "    \n",
    "    image = cv2.resize(unscaled, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
    "\n",
    "    region = irv2.predict(x=np.array([feat_scaled]))[0]\n",
    "\n",
    "    x1a = (region[0] * image_width / IMAGE_SIZE)\n",
    "    y1a = (region[1] * image_height / IMAGE_SIZE)\n",
    "\n",
    "    x2a = ((region[0] + region[2]) * image_width / IMAGE_SIZE)\n",
    "    y2a = ((region[1] + region[3]) * image_height / IMAGE_SIZE)\n",
    "    \n",
    "    IMAGE_SIZE = 224\n",
    "\n",
    "    image = cv2.resize(unscaled, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
    "\n",
    "    region = mnv2.predict(x=np.array([feat_scaled]))[0]\n",
    "\n",
    "    x1b = (region[0] * image_width / IMAGE_SIZE)\n",
    "    y1b = (region[1] * image_height / IMAGE_SIZE)\n",
    "\n",
    "    x2b = ((region[0] + region[2]) * image_width / IMAGE_SIZE)\n",
    "    y2b = ((region[1] + region[3]) * image_height / IMAGE_SIZE)\n",
    "\n",
    "\n",
    "    sample.iloc[index,1] = int((x1a + x1b)/2)\n",
    "    sample.iloc[index,2] = int((x2a + x2b)/2)\n",
    "    sample.iloc[index,3] = int((y1a + y1b)/2)\n",
    "    sample.iloc[index,4] = int((y2a + y2b)/2)\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_absolute_error\", optimizer=\"adadelta\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = Validation(generator=DataGenerator(VALIDATION_CSV, batch_size = 64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
